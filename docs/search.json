[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "The goal of these models is to see how different lifestyle choices affect the likelihood of an American having diabetes. This will include diet, exercise, and smoking habits."
  },
  {
    "objectID": "Modeling.html#about-the-models",
    "href": "Modeling.html#about-the-models",
    "title": "Modeling",
    "section": "",
    "text": "The goal of these models is to see how different lifestyle choices affect the likelihood of an American having diabetes. This will include diet, exercise, and smoking habits."
  },
  {
    "objectID": "Modeling.html#preparing-data-for-models",
    "href": "Modeling.html#preparing-data-for-models",
    "title": "Modeling",
    "section": "Preparing Data for Models",
    "text": "Preparing Data for Models\nFirst I will read in the data again, subsetting it the same it was in the EDA.\n\n## reading in data again\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntemp_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\", col_names = TRUE)\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n## subsetting the data\ndia_data &lt;- temp_data |&gt;\n  select(Diabetes_binary, BMI, Smoker, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, MentHlth, PhysHlth) |&gt;\n  drop_na() |&gt;\n  # turning binary vars into factors\n  mutate(Diabetes_binary = factor(Diabetes_binary, levels = c(0, 1), labels = c(\"no diabetes\", \"diabetes\"))) |&gt;\n  mutate(Smoker = factor(Smoker, levels = c(0, 1), labels = c(\"has not smoked 5 packs\", \"has smoked 5 packs\"))) |&gt;\n  mutate(PhysActivity = factor(PhysActivity, levels = c(0, 1), labels = c(\"no exercise last 30 days\", \"has exercised last 30 days\"))) |&gt;\n  mutate(Fruits = factor(Fruits, levels = c(0, 1), labels = c(\"does not eat fruit daily\", \"eats fruit daily\"))) |&gt;\n  mutate(Veggies = factor(Veggies, levels = c(0, 1), labels = c(\"does not eat veggies daily\", \"eats veggies daily\"))) |&gt;\n  mutate(HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1), labels = c(\"not a heavy drinker\", \"heavy drinker\")))\n\nnames_vec &lt;- c(\"dia_binary\",\"bmi\", \"smoker\", \"exercise\", \"fruits\", \"veggies\", \"alcohol\", \"ment_hlth\", \"phys_hlth\")\nnames(dia_data) &lt;- names_vec\n\nNow I will do a 70/30 split for the training/testing data sets.\n\n## splitting the data\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nset.seed(123)\ndia_split &lt;- initial_split(dia_data, 0.7)\ndia_train &lt;- training(dia_split)\ndia_test &lt;- testing(dia_split)\n\n## set up for cross validation\ndia_5_fold &lt;- vfold_cv(dia_train, 5)"
  },
  {
    "objectID": "Modeling.html#classification-tree",
    "href": "Modeling.html#classification-tree",
    "title": "Modeling",
    "section": "Classification Tree",
    "text": "Classification Tree\nA classification tree is a model that splits up predictor space into regions. Then a prediction is made based on which bin an observation ends up in. The goal is to predict group membership, usually using the most prevalent class in a region as the prediction.\n\nset.seed(123)\n## creating the tree recipe\ntree_rec &lt;-\n  recipe(dia_binary ~ ., data = dia_data) |&gt;\n  step_dummy(smoker, exercise, fruits, veggies, alcohol) |&gt;\n  step_normalize(all_numeric(), -all_outcomes())\n\n## defining the tree model\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n = 20,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n## creating the tree workflow\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(tree_rec) |&gt;\n  add_model(tree_mod)\n\n## creating the tree tuning grid\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = c(10, 5))\n\n## fitting the tree model\ntree_fits &lt;- tree_wkf |&gt; \n  tune_grid(resamples = dia_5_fold,\n            grid = tree_grid,\n            metrics = metric_set(mn_log_loss))\n\n\nset.seed(123)\n## selecting the best model\ntree_best_params &lt;- tree_fits |&gt;\n  select_best(metric = \"mn_log_loss\")\n\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(dia_split, metrics = metric_set(mn_log_loss))\n\ntree_best_fit &lt;- tree_final_fit |&gt;\n  collect_metrics()\n\ntree_best_fit\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.371 Preprocessor1_Model1"
  },
  {
    "objectID": "Modeling.html#random-forest",
    "href": "Modeling.html#random-forest",
    "title": "Modeling",
    "section": "Random Forest",
    "text": "Random Forest\nA random forest is a model that combines multiple classification trees that are created from boostrap samples. It uses the aggregate from the trees to find an average across them all. Additionally, it does not use all predictors in each step. It can be a useful alternative to a single classification tree as those are prone to over fitting. As a result, it may produce a better model.\n\nset.seed(123)\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.4.2\n\n## defining the rf model\nrf_spec &lt;- rand_forest(mtry = tune()) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"classification\")\n\n## creating the rf workflow\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(tree_rec) |&gt;\n  add_model(rf_spec)\n\n## fitting the rf model\nrf_fits &lt;- rf_wkf |&gt; \n  tune_grid(resamples = dia_5_fold,\n            grid = 5,\n            metrics = metric_set(mn_log_loss))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n\nset.seed(123)\n## selecting the best model\nrf_best_params &lt;- rf_fits |&gt;\n  select_best(metric = \"mn_log_loss\")\n\nrf_final_wkf &lt;- rf_wkf |&gt;\n  finalize_workflow(rf_best_params)\n\nrf_final_fit &lt;- rf_final_wkf |&gt;\n  last_fit(dia_split, metrics = metric_set(mn_log_loss))\n\nrf_best_fit &lt;- rf_final_fit |&gt;\n  collect_metrics()\n\nrf_best_fit\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.375 Preprocessor1_Model1\n\n\nThe Classification Tree is the better model in the case as it produces a smaller log loss."
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "This data set provides information on over 200,000 Americans from 2015 with the primary response variable being whether the person is diabetic. I will be analyzing to see how and what lifestyle choices result in a higher chance of diabetes among Americans. This will include diet, exercise, and smoking habits. The goal is to see how much these different lifestyle choices can increase the risk of diabetes among Americans."
  },
  {
    "objectID": "EDA.html#about-the-data",
    "href": "EDA.html#about-the-data",
    "title": "EDA",
    "section": "",
    "text": "This data set provides information on over 200,000 Americans from 2015 with the primary response variable being whether the person is diabetic. I will be analyzing to see how and what lifestyle choices result in a higher chance of diabetes among Americans. This will include diet, exercise, and smoking habits. The goal is to see how much these different lifestyle choices can increase the risk of diabetes among Americans."
  },
  {
    "objectID": "EDA.html#data-preparation",
    "href": "EDA.html#data-preparation",
    "title": "EDA",
    "section": "Data Preparation",
    "text": "Data Preparation\nFirst I will be subsetting the data set to only use the variables that I need for my analysis. I will also be converting the binary numerical variables into factors with meaningful level names.\n\n## reading in the data\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntemp_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\", col_names = TRUE)\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n## subsetting the data\ndia_data &lt;- temp_data |&gt;\n  select(Diabetes_binary, BMI, Smoker, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, MentHlth, PhysHlth) |&gt;\n  drop_na() |&gt;\n  # turning binary vars into factors\n  mutate(Diabetes_binary = factor(Diabetes_binary, levels = c(0, 1), labels = c(\"no diabetes\", \"diabetes\"))) |&gt;\n  mutate(Smoker = factor(Smoker, levels = c(0, 1), labels = c(\"has not smoked 5 packs\", \"has smoked 5 packs\"))) |&gt;\n  mutate(PhysActivity = factor(PhysActivity, levels = c(0, 1), labels = c(\"no exercise last 30 days\", \"has exercised last 30 days\"))) |&gt;\n  mutate(Fruits = factor(Fruits, levels = c(0, 1), labels = c(\"does not eat fruit daily\", \"eats fruit daily\"))) |&gt;\n  mutate(Veggies = factor(Veggies, levels = c(0, 1), labels = c(\"does not eat veggies daily\", \"eats veggies daily\"))) |&gt;\n  mutate(HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1), labels = c(\"not a heavy drinker\", \"heavy drinker\")))\n\nnames_vec &lt;- c(\"dia_binary\",\"bmi\", \"smoker\", \"exercise\", \"fruits\", \"veggies\", \"alcohol\", \"ment_hlth\", \"phys_hlth\")\nnames(dia_data) &lt;- names_vec\nstr(dia_data)\n\ntibble [253,680 × 9] (S3: tbl_df/tbl/data.frame)\n $ dia_binary: Factor w/ 2 levels \"no diabetes\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ bmi       : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ smoker    : Factor w/ 2 levels \"has not smoked 5 packs\",..: 2 2 1 1 1 2 2 2 2 1 ...\n $ exercise  : Factor w/ 2 levels \"no exercise last 30 days\",..: 1 2 1 2 2 2 1 2 1 1 ...\n $ fruits    : Factor w/ 2 levels \"does not eat fruit daily\",..: 1 1 2 2 2 2 1 1 2 1 ...\n $ veggies   : Factor w/ 2 levels \"does not eat veggies daily\",..: 2 1 1 2 2 2 1 2 2 2 ...\n $ alcohol   : Factor w/ 2 levels \"not a heavy drinker\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ ment_hlth : num [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ phys_hlth : num [1:253680] 15 0 30 0 0 2 14 0 30 0 ..."
  },
  {
    "objectID": "EDA.html#data-summarization",
    "href": "EDA.html#data-summarization",
    "title": "EDA",
    "section": "Data Summarization",
    "text": "Data Summarization\nNow I will see how frequent diabetes is among those with the different levels of the other factor variables. With the exception of heavy alcohol consumption, diabetics appear to be more likely to partake in the unhealthy lifestyle choices.\n\n## contingency tables\ntable(dia_data$dia_binary, dia_data$smoker)\n\n             \n              has not smoked 5 packs has smoked 5 packs\n  no diabetes                 124228              94106\n  diabetes                     17029              18317\n\ntable(dia_data$dia_binary, dia_data$exercise)\n\n             \n              no exercise last 30 days has exercised last 30 days\n  no diabetes                    48701                     169633\n  diabetes                       13059                      22287\n\ntable(dia_data$dia_binary, dia_data$fruits)\n\n             \n              does not eat fruit daily eats fruit daily\n  no diabetes                    78129           140205\n  diabetes                       14653            20693\n\ntable(dia_data$dia_binary, dia_data$veggies)\n\n             \n              does not eat veggies daily eats veggies daily\n  no diabetes                      39229             179105\n  diabetes                          8610              26736\n\ntable(dia_data$dia_binary, dia_data$alcohol)\n\n             \n              not a heavy drinker heavy drinker\n  no diabetes              204910         13424\n  diabetes                  34514           832\n\n\nNow I will create graphs to better visual some of these findings.\n\n## basic plots\nggplot(dia_data, aes(x = dia_binary, fill = smoker)) +\n  geom_bar(position = \"dodge\") +\n  labs(x = \"Diabetic?\", title = \"Lifetime Smoking Habits Affect on Diabetes\")\n\n\n\n\n\n\n\nggplot(dia_data, aes(x = dia_binary, fill = fruits)) +\n  geom_bar(position = \"dodge\") +\n  labs(x = \"Diabetic?\", title = \"Fruit Eating Habits Affect on Diabetes\")\n\n\n\n\n\n\n\n\nThere are also a three numerical variables which I will be analyzing, BMI, Mental Health, Physical Health. The latter two variables are how many days the person has spent thinking about that type of health in the last 30 days. This shows that the average BMI is higher for those with diabetes than those without. The same is true for both Health variables.\n\ndia_data |&gt;\n  group_by(dia_binary) |&gt;\n  summarize(mean(bmi))\n\n# A tibble: 2 × 2\n  dia_binary  `mean(bmi)`\n  &lt;fct&gt;             &lt;dbl&gt;\n1 no diabetes        27.8\n2 diabetes           31.9\n\ndia_data |&gt;\n  group_by(dia_binary) |&gt;\n  summarize(mean(ment_hlth))\n\n# A tibble: 2 × 2\n  dia_binary  `mean(ment_hlth)`\n  &lt;fct&gt;                   &lt;dbl&gt;\n1 no diabetes              2.98\n2 diabetes                 4.46\n\ndia_data |&gt;\n  group_by(dia_binary) |&gt;\n  summarize(mean(phys_hlth))\n\n# A tibble: 2 × 2\n  dia_binary  `mean(phys_hlth)`\n  &lt;fct&gt;                   &lt;dbl&gt;\n1 no diabetes              3.64\n2 diabetes                 7.95\n\nggplot(dia_data, aes(x = dia_binary, y = bmi)) +\n  geom_boxplot() +\n  labs(x = \"Diabetic?\", title = \"BMI of People with and without Diabetes\")\n\n\n\n\n\n\n\n\nClick here for the Modeling Page"
  }
]